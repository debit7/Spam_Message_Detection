{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbc15df1-3c78-475e-a43c-15a44bdd999b",
   "metadata": {},
   "source": [
    "Project: **Machine Learning Programming Project 2 Part 2** \n",
    "<br>\n",
    "Team Members: **Debit Paudel, Kushal Dahal**\n",
    "<br>\n",
    "We have used github for the collaboration.\n",
    "<br>\n",
    "Github Link: https://github.com/debit7/Spam_Message_Detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276478fe-0d0b-40d6-a356-faa2046decbb",
   "metadata": {},
   "source": [
    "Starting to working on the dataset of messages where there were two attributes: Classifier, Messages. All of the messages are classified as spam and ham in the classifier. Initially we have read the data using open() and panda to build a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "90967095-0386-469b-ab6b-1ab6af7c4dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Messages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classifier                                           Messages\n",
       "0        ham  Go until jurong point, crazy.. Available only ...\n",
       "1        ham                      Ok lar... Joking wif u oni...\n",
       "2       spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3        ham  U dun say so early hor... U c already then say...\n",
       "4        ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "with open('spam.data') as f:\n",
    "        lst = []\n",
    "        for ele in f:\n",
    "            line = ele.replace('\\n','').split('\\t')\n",
    "            \n",
    "            lst.append(line)\n",
    "Headers=['Classifier','Messages']\n",
    "df = pd.DataFrame(lst,columns =Headers) \n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8092dc6d-7d8f-4789-b3c2-26dad565f075",
   "metadata": {},
   "source": [
    "After building a dataframe, we splitted the dataset into training and testing dataset 75:25 ratio. Pre processing of training dataset plays a important role in the accuracy of the model. We started to remove the punctuations, created stop words dictionary and removed those words from our training dataset. Working on splitting the single message into words, we listed all the unique words in a list:wordlist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "7d9fdde0-96a6-4c13-97d9-e04f33447335",
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomly splitting data in training and testing data set\n",
    "training = df.sample(frac=0.75)\n",
    "testing = df.drop(training.index)\n",
    "#print(training)\n",
    "#print(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "2bd52143-6c0c-4c6a-809f-31526536da3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing punctuations from the messages and converting the upper cases to lower case\n",
    "punctuations='''€˜%^&\"\\,!*_~)(-[};:]{'<#£$>./?@+'''\n",
    "stop_words=[\"i\",\"da\",\"we\",\"ur\" ,\"u\",\"am\",\"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]\n",
    "wordlist=[]\n",
    "for message in training['Messages']:\n",
    "    \n",
    "    #print(message,'\\n')\n",
    "    for alpha in message:\n",
    "        if alpha in punctuations:\n",
    "            message = message.replace(alpha, \" \")\n",
    "    #for lower case        \n",
    "    message=message.lower()\n",
    "    \n",
    "    #for stop words\n",
    "    message=message.split()\n",
    "    #print(message)\n",
    "    for word in message:\n",
    "        if word in stop_words:\n",
    "            #print(word,'\\n')\n",
    "            message.remove(word)\n",
    "        wordlist.append(word)\n",
    "wordlist=list(set(wordlist))\n",
    "Vocabulary = len(wordlist) \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ede7297-6365-4aea-a34e-19aee0630fb8",
   "metadata": {},
   "source": [
    "With an completion of building a wordlist with distinct words from all the messages in training set, we built a new training table containing each word of the wordlist as an column resulting 6218 columns. After building this table structure, we counted the frequency of each word in each message for all the training rows and the frequency is stored in the word attribute column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "0231b638-71f7-435a-9574-fe51fef82f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating frequency for each word in a message\n",
    "word_counts_per_Messages=[\n",
    "    [row[1].count(word) for word in wordlist]\n",
    "    for _, row in training.iterrows()]\n",
    "df_wordcount=pd.DataFrame(word_counts_per_Messages,columns=wordlist)\n",
    "training = pd.concat([training.reset_index(), df_wordcount], axis=1).iloc[:,1:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da552124-8433-4294-a175-f5481e290e4f",
   "metadata": {},
   "source": [
    "While working in the calculations for naive bayes, initially we calculated the classifiers probability based on training set. We created list for spam and ham classifiers. Calculated the total number of word positions for spam and ham classifiers. After the calculation of number of times word occurs in the particular classifier,total number of word positions in the particular classifier, we built different functions for each classifier to estimate the word occurrence of that particular message type. While building these functions, we felt there can be words that did not appear in training set but may appear in the test set. Our model may assign a probability of 0. To prevent this problem that may appear in future, we added 1 in the numerator and the length of the wordlist i.e |Vocabulary| in the denominator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "ab454ad3-2033-4fc7-980b-a3bc1019cddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_probability = training['Classifier'].value_counts()['spam'] / len(training)\n",
    "ham_probability = training['Classifier'].value_counts()['ham'] / len(training)\n",
    "spam_list=training['Classifier'] == 'spam'\n",
    "ham_list=training['Classifier'] == 'ham'\n",
    "spam = training[spam_list]\n",
    "ham = training[ham_list]\n",
    "spam_n = training.loc[spam_list, 'Messages'].apply(len).sum()\n",
    "ham_n = training.loc[ham_list, 'Messages'].apply(len).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "0dc1795b-a9ef-409a-a848-706ff283f0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_word_spam(word):\n",
    "        return (spam[word].sum() + 1) / (spam_n + Vocabulary) if word in training.columns else 1\n",
    "   \n",
    "def probability_word_ham(word):\n",
    "         return (ham[word].sum() + 1) / (ham_n + Vocabulary) if word in training.columns else 1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b05162-4b3f-4d95-832f-b8708196c82b",
   "metadata": {},
   "source": [
    "With an aim to predict the classifier of all the test data sets, we created a dynamic function to classify the message as spam and ham. Here while we were multiplying each small probabilities, the calculation may result an arithmetic underflow. So to prevent this kind of issue, we implemented logarithms base 10 importing math library avoiding the underflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "76c1e5a5-ab91-48a2-a017-2789bad7becb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math as mt\n",
    "def naive_classifier(Message):\n",
    "    prob_spam = spam_probability\n",
    "    prob_ham = ham_probability\n",
    "    for word in Message:\n",
    "        prob_spam += mt.log(probability_word_spam(word),10)\n",
    "        prob_ham += mt.log(probability_word_ham(word),10)\n",
    "    prob_spam=10**prob_spam\n",
    "    prob_ham=10**prob_ham\n",
    "    return 'ham' if prob_ham > prob_spam else 'spam'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "5807acb0-f24b-49cf-8beb-a84e2bd9b381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of this model: 96.12625538020086\n"
     ]
    }
   ],
   "source": [
    "testing['Predicted_label'] = testing['Messages'].apply(naive_classifier)\n",
    "Accuracy = (testing['Predicted_label'] == testing['Classifier']).sum() / len(testing) * 100\n",
    "print(\"Accuracy of this model:\",Accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c81807-b2b2-4462-87bb-64f93c210fd3",
   "metadata": {},
   "source": [
    "While predicting the messages creating new column: Predicted_label, we also calculated the accuracy of our model based on the prediction of testing dataset and got the accuracy of 96%. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef62e80d-01b4-4f1c-93ff-16ba74239153",
   "metadata": {},
   "source": [
    "**Approach :**\n",
    "<br>\n",
    "We followed the approach of bayes algorithm considering each word in the distinct wordlist of training set as an attribute and estimated the word occurrence of that particular message type. \n",
    "<br>\n",
    "**Problems**\n",
    "<br>\n",
    "We faced several problems while working on this project. We faced problems to create attributes for each word in the training set and to calculate the frequency. We tried nested loop to do this task. But it was time consuming. So we found out that inline forloop and pandas iterrows() can do the same task in short about of time.\n",
    "<br>\n",
    "**Experiment**\n",
    "<br>\n",
    "Experiment 1:\n",
    "<br>\n",
    "While experimenting the classifying function without implementing logarithm base 10, multiplying each small probabilities result an arithmetic underflow and the accuracy was 94%. But after the implementation of logarithm base 10 the accuracy increased upto 96%\n",
    "<br>\n",
    "Experiment 2:\n",
    "<br>\n",
    "Another experiment we conducted was we did not remove punctuations and stop words intially. The accuracy was not good i.e 88%. So we removed punctuations and stop words. The accuracy was raised to 96%.\n",
    "<br>\n",
    "Experiment 3:\n",
    "<br>\n",
    "Another experiment we conducted was we separated training and testing datasets as 60:40 proportion and got the accuracy of 94%. While comparing the accuracy with the experiment where the dataset was classified into 75-25 for training and testing sets,the accuracy was raised to 96%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "08da86b6-da18-4e7e-a3f1-f2ff3d49c7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of this model without using Logarithm: 94.33285509325682\n"
     ]
    }
   ],
   "source": [
    "#Experiment 1: without using logarithms \n",
    "training = df.sample(frac=0.75)\n",
    "testing = df.drop(training.index)\n",
    "wordlist=[]\n",
    "for message in training['Messages']:\n",
    "    \n",
    "    for alpha in message:\n",
    "        if alpha in punctuations:\n",
    "            message = message.replace(alpha, \" \")\n",
    "    #for lower case        \n",
    "    message=message.lower()\n",
    "    \n",
    "    #for stop words\n",
    "    message=message.split()\n",
    "    #print(message)\n",
    "    for word in message:\n",
    "        if word in stop_words:\n",
    "            #print(word,'\\n')\n",
    "            message.remove(word)\n",
    "        wordlist.append(word)\n",
    "wordlist=list(set(wordlist))\n",
    "Vocabulary = len(wordlist) \n",
    "word_counts_per_Messages=[\n",
    "    [row[1].count(word) for word in wordlist]\n",
    "    for _, row in training.iterrows()]\n",
    "df_wordcount=pd.DataFrame(word_counts_per_Messages,columns=wordlist)\n",
    "training = pd.concat([training.reset_index(), df_wordcount], axis=1).iloc[:,1:]\n",
    "spam_probability = training['Classifier'].value_counts()['spam'] / len(training)\n",
    "ham_probability = training['Classifier'].value_counts()['ham'] / len(training)\n",
    "spam_list=training['Classifier'] == 'spam'\n",
    "ham_list=training['Classifier'] == 'ham'\n",
    "spam = training[spam_list]\n",
    "ham = training[ham_list]\n",
    "spam_n = training.loc[spam_list, 'Messages'].apply(len).sum()\n",
    "ham_n = training.loc[ham_list, 'Messages'].apply(len).sum()\n",
    "def probability_word_spam(word):\n",
    "        return (spam[word].sum() + 1) / (spam_n + Vocabulary) if word in training.columns else 1\n",
    "   \n",
    "def probability_word_ham(word):\n",
    "        return (ham[word].sum() + 1) / (ham_n + Vocabulary) if word in training.columns else 1\n",
    "\n",
    "def naive_classifier(Message):\n",
    "    prob_spam = spam_probability\n",
    "    prob_ham = ham_probability\n",
    "    for word in Message:\n",
    "        prob_spam *= probability_word_spam(word)\n",
    "        prob_ham *=probability_word_ham(word)\n",
    "    return 'ham' if prob_ham > prob_spam else 'spam'\n",
    "testing['Predicted_label'] = testing['Messages'].apply(naive_classifier)\n",
    "Accuracy = (testing['Predicted_label'] == testing['Classifier']).sum() / len(testing) * 100\n",
    "print(\"Accuracy of this model without using Logarithm:\",Accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "909a3026-6125-4798-941a-01c898de828a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of this model: 88.30703012912483\n"
     ]
    }
   ],
   "source": [
    "#Experiment 2: Without cleaning the punctuation and stop words\n",
    "training = df.sample(frac=0.75)\n",
    "testing = df.drop(training.index)\n",
    "wordlist=[]\n",
    "for message in training['Messages']:\n",
    "    message=message.split()\n",
    "    for word in message:\n",
    "        wordlist.append(word)\n",
    "wordlist=list(set(wordlist))\n",
    "Vocabulary = len(wordlist) \n",
    "word_counts_per_Messages=[\n",
    "    [row[1].count(word) for word in wordlist]\n",
    "    for _, row in training.iterrows()]\n",
    "df_wordcount=pd.DataFrame(word_counts_per_Messages,columns=wordlist)\n",
    "training = pd.concat([training.reset_index(), df_wordcount], axis=1).iloc[:,1:]\n",
    "spam_probability = training['Classifier'].value_counts()['spam'] / len(training)\n",
    "ham_probability = training['Classifier'].value_counts()['ham'] / len(training)\n",
    "spam_list=training['Classifier'] == 'spam'\n",
    "ham_list=training['Classifier'] == 'ham'\n",
    "spam = training[spam_list]\n",
    "ham = training[ham_list]\n",
    "spam_n = training.loc[spam_list, 'Messages'].apply(len).sum()\n",
    "ham_n = training.loc[ham_list, 'Messages'].apply(len).sum()\n",
    "def probability_word_spam(word):\n",
    "        return (spam[word].sum() + 1) / (spam_n + Vocabulary) if word in training.columns else 1\n",
    "   \n",
    "def probability_word_ham(word):\n",
    "        return (ham[word].sum() + 1) / (ham_n + Vocabulary) if word in training.columns else 1\n",
    "import math as mt\n",
    "def naive_classifier(Message):\n",
    "    prob_spam = spam_probability\n",
    "    prob_ham = ham_probability\n",
    "    for word in Message:\n",
    "        prob_spam += mt.log(probability_word_spam(word),10)\n",
    "        prob_ham += mt.log(probability_word_ham(word),10)\n",
    "    prob_spam=10**prob_spam\n",
    "    prob_ham=10**prob_ham\n",
    "    return 'ham' if prob_ham > prob_spam else 'spam'\n",
    "testing['Predicted_label'] = testing['Messages'].apply(naive_classifier)\n",
    "Accuracy = (testing['Predicted_label'] == testing['Classifier']).sum() / len(testing) * 100\n",
    "print(\"Accuracy of this model:\",Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "97be42bc-54a6-4828-ad93-e193f5f2bca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of this model implementing 60:40 training:testing proportion: 94.84304932735425\n"
     ]
    }
   ],
   "source": [
    "#Experiment 3: partitioning training and testing data sets as 60:40\n",
    "training = df.sample(frac=0.6)\n",
    "testing = df.drop(training.index)\n",
    "punctuations='''€˜%^&\"\\,!*_~)(-[};:]{'<#£$>./?@+'''\n",
    "stop_words=[\"i\",\"da\",\"we\",\"ur\" ,\"u\",\"am\",\"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]\n",
    "wordlist=[]\n",
    "for message in training['Messages']:\n",
    "    \n",
    "    for alpha in message:\n",
    "        if alpha in punctuations:\n",
    "            message = message.replace(alpha, \" \")\n",
    "    #for lower case        \n",
    "    message=message.lower()\n",
    "    \n",
    "    #for stop words\n",
    "    message=message.split()\n",
    "    #print(message)\n",
    "    for word in message:\n",
    "        if word in stop_words:\n",
    "            #print(word,'\\n')\n",
    "            message.remove(word)\n",
    "        wordlist.append(word)\n",
    "wordlist=list(set(wordlist))\n",
    "Vocabulary = len(wordlist) \n",
    "word_counts_per_Messag=[\n",
    "    [row[1].count(word) for word in wordlist]\n",
    "    for _, row in training.iterrows()]\n",
    "df_wordcount=pd.DataFrame(word_counts_per_Messag,columns=wordlist)\n",
    "training = pd.concat([training.reset_index(), df_wordcount], axis=1).iloc[:,1:]\n",
    "spam_probability = training['Classifier'].value_counts()['spam'] / len(training)\n",
    "ham_probability = training['Classifier'].value_counts()['ham'] / len(training)\n",
    "spam_list=training['Classifier'] == 'spam'\n",
    "ham_list=training['Classifier'] == 'ham'\n",
    "spam = training[spam_list]\n",
    "ham = training[ham_list]\n",
    "spam_n = training.loc[spam_list, 'Messages'].apply(len).sum()\n",
    "ham_n = training.loc[ham_list, 'Messages'].apply(len).sum()\n",
    "def probability_word_spam(word):\n",
    "        return (spam[word].sum() + 1) / (spam_n + Vocabulary) if word in training.columns else 1\n",
    "   \n",
    "def probability_word_ham(word):\n",
    "        return (ham[word].sum() + 1) / (ham_n + Vocabulary) if word in training.columns else 1\n",
    "\n",
    "def naive_classifier(Message):\n",
    "    prob_spam = spam_probability\n",
    "    prob_ham = ham_probability\n",
    "    for word in Message:\n",
    "        prob_spam *= probability_word_spam(word)\n",
    "        prob_ham *=probability_word_ham(word)\n",
    "    return 'ham' if prob_ham > prob_spam else 'spam'\n",
    "testing['Predicted_label'] = testing['Messages'].apply(naive_classifier)\n",
    "\n",
    "Accuracy = (testing['Predicted_label'] == testing['Classifier']).sum() / len(testing) * 100\n",
    "print(\"Accuracy of this model implementing 60:40 training:testing proportion:\",Accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce75fcb0-0a43-4854-a6c1-86e6856316d4",
   "metadata": {},
   "source": [
    "**Effectiveness of our classifier comparing with random guessing:**\n",
    "<br>\n",
    "In our case, there are two classifiers for the messages spam,ham. Even a random guess choosing out of these two classes has the probability 1/2 to choose correct class.With an simple logic we can say that the expected accuracy is 50%. Looking at this accuracy, we know that our classifier is trained well to predict the class with 96% accuracy.\n",
    "Again when we consider the basic two hypothesis for the random guess, one is the best case and other is the worst case. For the best case of the random choice, it may get 100 % accuracy with a very low probability whereas our classifier will never reach upto 100 %.\n",
    "But while considering the worst hypothesis, the random guess can have 0 % accuracy and classify all of the messages wrong with certainity. This can never happen with our classifier whose accuracy is 96%. \n",
    "\n",
    "So while concluding, though our classifier may not get 100 % accuracy on both best and worst case but it may never get an accuracy of 0% wrongly classifying the messages with certainity."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
